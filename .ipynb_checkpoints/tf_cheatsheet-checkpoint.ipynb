{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow cheatsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"tensorflow\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea of session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# tf.enable_eager_execution()\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.constant(2)\n",
    "w1 = tf.Variable(2)\n",
    "\n",
    "x = tf.constant(5)\n",
    "x1 = tf.Variable(5)\n",
    "\n",
    "y = w*(x**2)\n",
    "z = w*x+2\n",
    "\n",
    "y1 = w1*(x1**2)\n",
    "z1 = w1*x1+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()    # prepare an init node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resultvalue: <class 'numpy.int32'>\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = sess.run(y)\n",
    "    print(\"resultvalue: {0}\".format(type(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constant_eval():\n",
    "    y.eval()\n",
    "    z.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_eval():\n",
    "    y1.eval()\n",
    "    z1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213 µs ± 10.8 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "147 µs ± 1.35 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "250 µs ± 5.86 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "173 µs ± 1.56 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    %timeit constant_eval()    # evaluate y, z twice\n",
    "    %timeit y_val, z_val = sess.run([y, z])    # evaluate y, z in 1 graph run\n",
    "    %timeit variable_eval()\n",
    "    %timeit y1_val, z1_val = sess.run([y1, z1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "constant-structure is algorithmically less time-perplexing than Variable-structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GD with manual derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "always remember to apply feature-scaling (data normalization) before GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "x = np.c_[np.ones((m, 1)), scaled_housing_data]\n",
    "y = housing.target\n",
    "w = np.random.randn(n+1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setup nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 2000\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.constant(x, dtype=tf.float32, name=\"X\")\n",
    "Y = tf.constant(housing.target.reshape(-1 ,1),dtype=tf.float32, name=\"Y\")\n",
    "W = tf.Variable(w,dtype=tf.float32, name=\"W\")        # internal model parameters\n",
    "www = W+2    # www has been implicitly been extened as tf.Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predict = tf.matmul(X, W, name=\"prediction\")\n",
    "error = Y_predict - Y\n",
    "loss = tf.losses.mean_squared_error(Y, Y_predict)\n",
    "gradients = 2/m*tf.matmul(tf.transpose(X), error)\n",
    " \n",
    "# cannot directly apply \"W = W - learning_rate*gradients\" since costant and Variable are \"source ops\" that take no input\n",
    "# W = W - learning_rate*gradients\n",
    "training_op = tf.assign(W, W - learning_rate*gradients)   \n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 0 :  MSE = 17.5893\n",
      "#Epoch 100 :  MSE = 1.06605\n",
      "#Epoch 200 :  MSE = 0.727634\n",
      "#Epoch 300 :  MSE = 0.668196\n",
      "#Epoch 400 :  MSE = 0.629465\n",
      "#Epoch 500 :  MSE = 0.601439\n",
      "#Epoch 600 :  MSE = 0.581019\n",
      "#Epoch 700 :  MSE = 0.566111\n",
      "#Epoch 800 :  MSE = 0.555209\n",
      "#Epoch 900 :  MSE = 0.547221\n",
      "#Epoch 1000 :  MSE = 0.541356\n",
      "#Epoch 1100 :  MSE = 0.537039\n",
      "#Epoch 1200 :  MSE = 0.533853\n",
      "#Epoch 1300 :  MSE = 0.531496\n",
      "#Epoch 1400 :  MSE = 0.529745\n",
      "#Epoch 1500 :  MSE = 0.528441\n",
      "#Epoch 1600 :  MSE = 0.527466\n",
      "#Epoch 1700 :  MSE = 0.526733\n",
      "#Epoch 1800 :  MSE = 0.526181\n",
      "#Epoch 1900 :  MSE = 0.525763\n",
      "optimal internal model parameters: [[ 2.06855226]\n",
      " [ 0.78806996]\n",
      " [ 0.11988165]\n",
      " [-0.1703423 ]\n",
      " [ 0.21964966]\n",
      " [-0.0035526 ]\n",
      " [-0.03853594]\n",
      " [-0.93066472]\n",
      " [-0.89567709]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    WWW = sess.run(www)\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"#Epoch\", epoch, \": \", \"MSE =\", loss.eval())\n",
    "        sess.run(training_op)\n",
    "        \n",
    "    best_W = W.eval()\n",
    "    print(\"optimal internal model parameters:\", best_W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GD with TF reverse-mode autodiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-211ebd772d73>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    gradients_autodiff = tf.gradients(loss, [W])    # eveything define with tf. is an operation including this...\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m\u001b[0;31m:\u001b[0m name 'loss' is not defined\n"
     ]
    }
   ],
   "source": [
    "gradients_autodiff = tf.gradients(loss, [W])    # eveything define with tf. is an operation including this...\n",
    "print(gradients_autodiff)\n",
    "training_op_autodiff = tf.assign(W, W - learning_rate*gradients_autodiff[0])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-4.94855881],\n",
      "       [-4.48504353],\n",
      "       [ 0.71529096],\n",
      "       [-2.399652  ],\n",
      "       [-0.89287376],\n",
      "       [ 0.0587704 ],\n",
      "       [ 3.94650126],\n",
      "       [-1.81760597],\n",
      "       [ 2.41193056]], dtype=float32)]\n",
      "#Epoch 0 :  MSE = 17.5893\n",
      "#Epoch 100 :  MSE = 1.06605\n",
      "#Epoch 200 :  MSE = 0.727634\n",
      "#Epoch 300 :  MSE = 0.668196\n",
      "#Epoch 400 :  MSE = 0.629465\n",
      "#Epoch 500 :  MSE = 0.601439\n",
      "#Epoch 600 :  MSE = 0.581019\n",
      "#Epoch 700 :  MSE = 0.566111\n",
      "#Epoch 800 :  MSE = 0.555209\n",
      "#Epoch 900 :  MSE = 0.547221\n",
      "#Epoch 1000 :  MSE = 0.541356\n",
      "#Epoch 1100 :  MSE = 0.537039\n",
      "#Epoch 1200 :  MSE = 0.533853\n",
      "#Epoch 1300 :  MSE = 0.531496\n",
      "#Epoch 1400 :  MSE = 0.529745\n",
      "#Epoch 1500 :  MSE = 0.528441\n",
      "#Epoch 1600 :  MSE = 0.527466\n",
      "#Epoch 1700 :  MSE = 0.526733\n",
      "#Epoch 1800 :  MSE = 0.526181\n",
      "#Epoch 1900 :  MSE = 0.525763\n",
      "optimal internal model parameters: [[ 2.06855249]\n",
      " [ 0.78806996]\n",
      " [ 0.11988167]\n",
      " [-0.17034236]\n",
      " [ 0.21964972]\n",
      " [-0.00355259]\n",
      " [-0.03853594]\n",
      " [-0.93066454]\n",
      " [-0.89567691]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    result = sess.run(gradients_autodiff)\n",
    "    print(result)\n",
    "    \n",
    "     \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"#Epoch\", epoch, \": \", \"MSE =\", loss.eval())\n",
    "        sess.run(training_op_autodiff)\n",
    "        \n",
    "    best_W = W.eval()\n",
    "    print(\"optimal internal model parameters:\", best_W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GD with TF optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to make GD computation even more abstract and intuitive..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'learning_rate' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-143d14dd9062>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m\u001b[0;31m:\u001b[0m name 'learning_rate' is not defined\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op_optimizer = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 0 :  MSE = 17.5893\n",
      "#Epoch 100 :  MSE = 1.06605\n",
      "#Epoch 200 :  MSE = 0.727634\n",
      "#Epoch 300 :  MSE = 0.668196\n",
      "#Epoch 400 :  MSE = 0.629465\n",
      "#Epoch 500 :  MSE = 0.601439\n",
      "#Epoch 600 :  MSE = 0.581019\n",
      "#Epoch 700 :  MSE = 0.566111\n",
      "#Epoch 800 :  MSE = 0.555209\n",
      "#Epoch 900 :  MSE = 0.547221\n",
      "#Epoch 1000 :  MSE = 0.541356\n",
      "#Epoch 1100 :  MSE = 0.537039\n",
      "#Epoch 1200 :  MSE = 0.533853\n",
      "#Epoch 1300 :  MSE = 0.531496\n",
      "#Epoch 1400 :  MSE = 0.529745\n",
      "#Epoch 1500 :  MSE = 0.528441\n",
      "#Epoch 1600 :  MSE = 0.527466\n",
      "#Epoch 1700 :  MSE = 0.526733\n",
      "#Epoch 1800 :  MSE = 0.526181\n",
      "#Epoch 1900 :  MSE = 0.525763\n",
      "optimal internal model parameters: [[ 2.06855249]\n",
      " [ 0.78806996]\n",
      " [ 0.11988167]\n",
      " [-0.17034236]\n",
      " [ 0.21964972]\n",
      " [-0.00355259]\n",
      " [-0.03853594]\n",
      " [-0.93066454]\n",
      " [-0.89567691]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"#Epoch\", epoch, \": \", \"MSE =\", loss.eval())\n",
    "        sess.run(training_op_optimizer)\n",
    "        \n",
    "    best_W = W.eval()\n",
    "    print(\"optimal internal model parameters:\", best_W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-batch GD with placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))    # np.float64-->int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "specify placeholder for batch stats input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float64, shape=(None, n+1), name=\"X\")\n",
    "Y = tf.placeholder(tf.float64, shape=(None, 1), name=\"Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "w = np.random.randn(n+1, 1)\n",
    "W = tf.Variable(w, name=\"W\", dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.matmul(X, W, name=\"preditions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = Y - y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss = tf.losses.mean_squared_error(Y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)    # optimize tf.Variable (internal model parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "specify logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_log/run-20190301075848/\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_dir = \"tf_log\"\n",
    "logdir = \"{}/run-{}/\".format(root_dir, now)\n",
    "print(logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "attach summary operation at the end of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_summary = tf.summary.scalar('MSE', loss)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_batch(epoch_index, batch_index, batch_size):\n",
    "    np.random.seed(epoch_index*batch_size+batch_index)\n",
    "    selected_samples = np.random.randint(m, size=batch_size)\n",
    "    X_batch = x[selected_samples]\n",
    "    Y_batch = y[selected_samples].reshape(-1, 1)\n",
    "    return X_batch, Y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the graph with print() & tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#batch 0 : MSE= 5.38999\n",
      "#batch 1 : MSE= 5.13267\n",
      "#batch 2 : MSE= 4.89256\n",
      "#batch 3 : MSE= 4.66839\n",
      "#batch 4 : MSE= 4.45898\n",
      "#batch 5 : MSE= 4.26322\n",
      "#batch 6 : MSE= 4.08013\n",
      "#batch 7 : MSE= 3.90877\n",
      "#batch 8 : MSE= 3.74829\n",
      "#batch 9 : MSE= 3.59791\n",
      "#batch 10 : MSE= 3.4569\n",
      "#batch 11 : MSE= 3.32458\n",
      "#batch 12 : MSE= 3.20036\n",
      "#batch 13 : MSE= 3.08364\n",
      "#batch 14 : MSE= 2.97391\n",
      "#batch 15 : MSE= 2.87067\n",
      "#batch 16 : MSE= 2.77349\n",
      "#batch 17 : MSE= 2.68193\n",
      "#batch 18 : MSE= 2.59563\n",
      "#batch 19 : MSE= 2.51421\n",
      "#batch 20 : MSE= 2.43736\n",
      "#batch 21 : MSE= 2.36477\n",
      "#batch 22 : MSE= 2.29615\n",
      "#batch 23 : MSE= 2.23125\n",
      "#batch 24 : MSE= 2.16982\n",
      "#batch 25 : MSE= 2.11164\n",
      "#batch 26 : MSE= 2.05649\n",
      "#batch 27 : MSE= 2.0042\n",
      "#batch 28 : MSE= 1.95457\n",
      "#batch 29 : MSE= 1.90745\n",
      "#batch 30 : MSE= 1.86267\n",
      "#batch 31 : MSE= 1.82009\n",
      "#batch 32 : MSE= 1.77958\n",
      "#batch 33 : MSE= 1.74102\n",
      "#batch 34 : MSE= 1.70428\n",
      "#batch 35 : MSE= 1.66927\n",
      "#batch 36 : MSE= 1.63587\n",
      "#batch 37 : MSE= 1.604\n",
      "#batch 38 : MSE= 1.57358\n",
      "#batch 39 : MSE= 1.54451\n",
      "#batch 40 : MSE= 1.51672\n",
      "#batch 41 : MSE= 1.49014\n",
      "#batch 42 : MSE= 1.46471\n",
      "#batch 43 : MSE= 1.44036\n",
      "#batch 44 : MSE= 1.41704\n",
      "#batch 45 : MSE= 1.39468\n",
      "#batch 46 : MSE= 1.37324\n",
      "#batch 47 : MSE= 1.35268\n",
      "#batch 48 : MSE= 1.33294\n",
      "#batch 49 : MSE= 1.31398\n",
      "#batch 50 : MSE= 1.29577\n",
      "#batch 51 : MSE= 1.27827\n",
      "#batch 52 : MSE= 1.26144\n",
      "#batch 53 : MSE= 1.24525\n",
      "#batch 54 : MSE= 1.22966\n",
      "#batch 55 : MSE= 1.21466\n",
      "#batch 56 : MSE= 1.20021\n",
      "#batch 57 : MSE= 1.18629\n",
      "#batch 58 : MSE= 1.17287\n",
      "#batch 59 : MSE= 1.15992\n",
      "#batch 60 : MSE= 1.14744\n",
      "#batch 61 : MSE= 1.13539\n",
      "#batch 62 : MSE= 1.12376\n",
      "#batch 63 : MSE= 1.11252\n",
      "#batch 64 : MSE= 1.10167\n",
      "#batch 65 : MSE= 1.09118\n",
      "#batch 66 : MSE= 1.08105\n",
      "#batch 67 : MSE= 1.07124\n",
      "#batch 68 : MSE= 1.06176\n",
      "#batch 69 : MSE= 1.05259\n",
      "#batch 70 : MSE= 1.04371\n",
      "#batch 71 : MSE= 1.03511\n",
      "#batch 72 : MSE= 1.02678\n",
      "#batch 73 : MSE= 1.01871\n",
      "#batch 74 : MSE= 1.01089\n",
      "#batch 75 : MSE= 1.00331\n",
      "#batch 76 : MSE= 0.995962\n",
      "#batch 77 : MSE= 0.988834\n",
      "#batch 78 : MSE= 0.981919\n",
      "#batch 79 : MSE= 0.975208\n",
      "#batch 80 : MSE= 0.968694\n",
      "#batch 81 : MSE= 0.962369\n",
      "#batch 82 : MSE= 0.956227\n",
      "#batch 83 : MSE= 0.950259\n",
      "#batch 84 : MSE= 0.944461\n",
      "#batch 85 : MSE= 0.938825\n",
      "#batch 86 : MSE= 0.933346\n",
      "#batch 87 : MSE= 0.928018\n",
      "#batch 88 : MSE= 0.922835\n",
      "#batch 89 : MSE= 0.917793\n",
      "#batch 90 : MSE= 0.912886\n",
      "#batch 91 : MSE= 0.90811\n",
      "#batch 92 : MSE= 0.90346\n",
      "#batch 93 : MSE= 0.898932\n",
      "#batch 94 : MSE= 0.89452\n",
      "#batch 95 : MSE= 0.890223\n",
      "#batch 96 : MSE= 0.886034\n",
      "#batch 97 : MSE= 0.881952\n",
      "#batch 98 : MSE= 0.877971\n",
      "#batch 99 : MSE= 0.874089\n",
      "#batch 100 : MSE= 0.870303\n",
      "#batch 101 : MSE= 0.866609\n",
      "#batch 102 : MSE= 0.863004\n",
      "#batch 103 : MSE= 0.859485\n",
      "#batch 104 : MSE= 0.856049\n",
      "#batch 105 : MSE= 0.852695\n",
      "#batch 106 : MSE= 0.849418\n",
      "#batch 107 : MSE= 0.846217\n",
      "#batch 108 : MSE= 0.843089\n",
      "#batch 109 : MSE= 0.840031\n",
      "#batch 110 : MSE= 0.837042\n",
      "#batch 111 : MSE= 0.83412\n",
      "#batch 112 : MSE= 0.831261\n",
      "#batch 113 : MSE= 0.828465\n",
      "#batch 114 : MSE= 0.82573\n",
      "#batch 115 : MSE= 0.823052\n",
      "#batch 116 : MSE= 0.820432\n",
      "#batch 117 : MSE= 0.817866\n",
      "#batch 118 : MSE= 0.815353\n",
      "#batch 119 : MSE= 0.812892\n",
      "#batch 120 : MSE= 0.810481\n",
      "#batch 121 : MSE= 0.808119\n",
      "#batch 122 : MSE= 0.805803\n",
      "#batch 123 : MSE= 0.803534\n",
      "#batch 124 : MSE= 0.801308\n",
      "#batch 125 : MSE= 0.799126\n",
      "#batch 126 : MSE= 0.796985\n",
      "#batch 127 : MSE= 0.794885\n",
      "#batch 128 : MSE= 0.792824\n",
      "#batch 129 : MSE= 0.790801\n",
      "#batch 130 : MSE= 0.788816\n",
      "#batch 131 : MSE= 0.786866\n",
      "#batch 132 : MSE= 0.784952\n",
      "#batch 133 : MSE= 0.783071\n",
      "#batch 134 : MSE= 0.781223\n",
      "#batch 135 : MSE= 0.779408\n",
      "#batch 136 : MSE= 0.777624\n",
      "#batch 137 : MSE= 0.77587\n",
      "#batch 138 : MSE= 0.774145\n",
      "#batch 139 : MSE= 0.77245\n",
      "#batch 140 : MSE= 0.770782\n",
      "#batch 141 : MSE= 0.769141\n",
      "#batch 142 : MSE= 0.767527\n",
      "#batch 143 : MSE= 0.765939\n",
      "#batch 144 : MSE= 0.764375\n",
      "#batch 145 : MSE= 0.762836\n",
      "#batch 146 : MSE= 0.76132\n",
      "#batch 147 : MSE= 0.759828\n",
      "#batch 148 : MSE= 0.758358\n",
      "#batch 149 : MSE= 0.756909\n",
      "#batch 150 : MSE= 0.755482\n",
      "#batch 151 : MSE= 0.754076\n",
      "#batch 152 : MSE= 0.75269\n",
      "#batch 153 : MSE= 0.751324\n",
      "#batch 154 : MSE= 0.749977\n",
      "#batch 155 : MSE= 0.748648\n",
      "#batch 156 : MSE= 0.747338\n",
      "#batch 157 : MSE= 0.746046\n",
      "#batch 158 : MSE= 0.744771\n",
      "#batch 159 : MSE= 0.743512\n",
      "#batch 160 : MSE= 0.742271\n",
      "#batch 161 : MSE= 0.741045\n",
      "#batch 162 : MSE= 0.739835\n",
      "#batch 163 : MSE= 0.73864\n",
      "#batch 164 : MSE= 0.73746\n",
      "#batch 165 : MSE= 0.736295\n",
      "#batch 166 : MSE= 0.735144\n",
      "#batch 167 : MSE= 0.734007\n",
      "#batch 168 : MSE= 0.732884\n",
      "#batch 169 : MSE= 0.731774\n",
      "#batch 170 : MSE= 0.730676\n",
      "#batch 171 : MSE= 0.729592\n",
      "#batch 172 : MSE= 0.72852\n",
      "#batch 173 : MSE= 0.727459\n",
      "#batch 174 : MSE= 0.726411\n",
      "#batch 175 : MSE= 0.725374\n",
      "#batch 176 : MSE= 0.724349\n",
      "#batch 177 : MSE= 0.723334\n",
      "#batch 178 : MSE= 0.72233\n",
      "#batch 179 : MSE= 0.721337\n",
      "#batch 180 : MSE= 0.720354\n",
      "#batch 181 : MSE= 0.719381\n",
      "#batch 182 : MSE= 0.718419\n",
      "#batch 183 : MSE= 0.717465\n",
      "#batch 184 : MSE= 0.716522\n",
      "#batch 185 : MSE= 0.715587\n",
      "#batch 186 : MSE= 0.714662\n",
      "#batch 187 : MSE= 0.713745\n",
      "#batch 188 : MSE= 0.712838\n",
      "#batch 189 : MSE= 0.711938\n",
      "#batch 190 : MSE= 0.711048\n",
      "#batch 191 : MSE= 0.710165\n",
      "#batch 192 : MSE= 0.70929\n",
      "#batch 193 : MSE= 0.708423\n",
      "#batch 194 : MSE= 0.707564\n",
      "#batch 195 : MSE= 0.706713\n",
      "#batch 196 : MSE= 0.705869\n",
      "#batch 197 : MSE= 0.705032\n",
      "#batch 198 : MSE= 0.704202\n",
      "#batch 199 : MSE= 0.70338\n",
      "#batch 200 : MSE= 0.702564\n",
      "#batch 201 : MSE= 0.701755\n",
      "#batch 202 : MSE= 0.700952\n",
      "#batch 203 : MSE= 0.700156\n",
      "#batch 204 : MSE= 0.699367\n",
      "#batch 205 : MSE= 0.698583\n",
      "#batch 206 : MSE= 0.697806\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches): \n",
    "            X_batch, Y_batch = fetch_batch(epoch, batch, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, Y: Y_batch})\n",
    "            step = epoch*n_batches + batch_index\n",
    "            # for every operation that depneds on training data, should pass in them through feed_dict\n",
    "            # visualize data with print()\n",
    "            if epoch in range(1):\n",
    "                    print(\"#batch\", step, \":\", \"MSE=\", sess.run(loss, feed_dict={X: X_batch, Y: Y_batch}))    \n",
    "                \n",
    "            # visualize data with tensorboard\n",
    "            summary_str = sess.run(loss_summary, feed_dict={X: X_batch, Y: Y_batch})\n",
    "            file_writer.add_summary(summary_str, step)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer.close() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
